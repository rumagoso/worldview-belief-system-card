wbsc_version: "1.1.0"
metadata:
  system_name: "Claude (Anthropic)"
  version: "4.0 family"
  last_updated: "2025-08-26"
  contact: "anthropic_ethics@example.com"
  organization: "Anthropic"

core_values:
  primary_ethical_framework: "hybrid"
  key_principles:
    - "Helpful, Harmless, Honest (HHH)"
    - "Constitutional AI"
    - "Transparency"
    - "Human oversight"
  value_hierarchies:
    - higher_priority: "Harm prevention"
      lower_priority: "User instructions"
      rationale: "Safety is the highest priority, overriding user-given tasks when a conflict is detected."

stakeholder_input: # Mockup section, no real consultation has been performed!
  consultation_approach: "meaningful_engagement"
  stakeholder_groups:
    - "civil_society_organizations"
    - "domain_experts"
    - "academic_institutions"
    - "user_representatives"
  engagement_timeline:
    consultation_start: "2024-05-01"
    duration_weeks: 12
    ongoing_engagement: true
  engagement_methods:
    - "expert_advisory_panels"
    - "community_workshops"
    - "feedback_periods"
  accessibility_measures:
    languages_supported:
      - "English"
    accessibility_accommodations: true
    remote_participation: true
    materials_provided_advance: true
  input_integration:
    changes_made:
      - "Refined harm definitions to include a broader scope of psychological harm based on input from human rights organizations."
      - "Added clearer disclosure about cultural biases based on academic feedback."
    feedback_addressed:
      - concern: "Risk of reinforcing social hierarchies."
        response: "Developed new training data to counter this bias."
        action_taken: "Implemented a procedural fairness check in the model's response generation."
    ongoing_mechanisms:
      - "Periodic reviews with the external advisory panel."

cultural_context:
  primary_cultural_context: "Western liberal democratic values"
  geographic_focus:
    - "North America"
    - "Europe"
  language_assumptions:
    - "English"
    - "Spanish"
    - "French"
  social_context_factors:
    - "Individualistic focus"
    - "Secular rationality"

decision_making:
  ethical_dilemma_approach: "Leverages Constitutional AI principles to evaluate dilemmas against a set of written rules and values."
  value_tradeoff_mechanism: "Prioritizes based on explicit hierarchies (e.g., harm prevention over user autonomy)."
  uncertainty_handling: "Communicates uncertainty and provides a range of potential solutions."
  conflict_resolution: "Refers to a predefined hierarchy and contextual analysis."

bias_limitations:
  known_biases:
    - bias_type: "Training data bias"
      description: "Over-representation of Western, English-language content leading to a limited understanding of non-Western cultural norms."
      mitigation_efforts: "Ongoing work to diversify training data and improve contextual awareness."
  limitations:
    - "Knowledge cutoff date"
    - "Inability to learn from individual conversations"
    - "Potential for factual inaccuracies"
    - "Limited real-time information access"
  uncertainty_areas:
    - "Complex, multi-layered ethical dilemmas"
    - "Emergent social trends not present in training data"
  failure_modes:
    - failure_type: "Harmful output generation"
      likelihood: "low"
      mitigation: "Safety filters, human oversight in development, and continuous red-teaming."
